{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5061deca-21ba-43f9-9d58-596b05f353ee",
   "metadata": {},
   "source": [
    "**NeoEEGTransformer**\n",
    "\n",
    "The **NeoEEGTransformer** is a custom neural network architecture specifically designed for seizure classification based on EEG signal. The transformer-based neural network was designed for the classification of multi-channel EEG data. Class imbalance in EEG data poses a significant challenge, often causing models to underperform on minority classes. To address this, SMOTE generates synthetic minority class samples by augmenting the dataset, which balances class distribution but may alter data characteristics. Alternatively, cost-sensitive learning uses class-weighted loss functions to penalize misclassifications of minority classes more heavily, improving recognition without changing the original data. Both approaches enhance model fairness and performance, with SMOTE focusing on data-level balancing and cost-sensitive learning emphasizing algorithm-level adjustments. Overall, the EEGTransformer model is designed to effectively process and classify EEG signals by combining normalization, positional encoding, attention mechanisms, and feed-forward processing. This makes it well-suited for applications in EEG analysis where capturing complex spatial-temporal relationships is critical.  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The model is engineered to capture complex spatial-temporal dynamics inherent in EEG signals through the following key components:\n",
    "\n",
    "- **Input and Preprocessing:**  \n",
    "  - **Input Shape:** The model expects EEG data in the shape `(batch_size, num_channels, num_timepoints)`.\n",
    "  - **Standardization:** Each sample is normalized along the time axis by subtracting the mean and dividing by the standard deviation.\n",
    "\n",
    "- **Positional Encoding:**  \n",
    "  - A fixed positional encoding is computed using sine and cosine functions across channels and time points.  \n",
    "  - This encoding is added to the normalized input to inject temporal information into the model, enabling it to distinguish the order of time points.\n",
    "\n",
    "- **Multi-Head Self-Attention:**  \n",
    "  - A multi-head attention mechanism captures relationships between different channels across time.\n",
    "  - This component allows the model to focus on relevant parts of the signal by computing attention weights.\n",
    "\n",
    "- **Feed-Forward Network (FFN) and Residual Connections:**  \n",
    "  - The attention outputs are passed through a feed-forward network consisting of two linear layers with a ReLU activation in between.\n",
    "  - Residual connections and layer normalization are applied to stabilize training and improve gradient flow.\n",
    "\n",
    "- **Classifier:**  \n",
    "  - The processed features are flattened and fed into a final linear layer that acts as the classifier, mapping the features to the desired output classes.\n",
    "\n",
    "- **Regularization:**  \n",
    "  - Dropout is employed within the attention layer to reduce overfitting and improve generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c56fcad-5ff9-4bd6-844d-39a7e54255e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve, auc, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import h5py\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve, confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import learning_curve\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f93ddf75-de2e-41b6-9b5f-e86f04c837c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EEG Transformer Model\n",
    "class EEGTransformer(nn.Module):\n",
    "    def __init__(self, num_channels=18, num_timepoints=64, output_dim=2,\n",
    "                 num_heads=6, intermediate_dim=128, ffn_output_dim=18):\n",
    "        super(EEGTransformer, self).__init__()\n",
    "        \n",
    "        # Build the positional encoding using math.sin and math.cos\n",
    "        positional_encoding = torch.zeros(num_channels, num_timepoints)\n",
    "        for j in range(num_channels):\n",
    "            for k in range(num_timepoints):\n",
    "                if j % 2 == 0:\n",
    "                    positional_encoding[j, k] = math.sin(k / (10000 ** (j / num_channels)))\n",
    "                else:\n",
    "                    positional_encoding[j, k] = math.cos(k / (10000 ** ((j - 1) / num_channels)))\n",
    "                    \n",
    "        # Register positional_encoding as a buffer so that it's moved to the correct device\n",
    "        self.register_buffer('positional_encoding', positional_encoding)\n",
    "        \n",
    "        self.multihead_attn = nn.MultiheadAttention(embed_dim=num_channels, num_heads=num_heads)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(num_channels, intermediate_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(intermediate_dim, ffn_output_dim)\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(num_channels)\n",
    "        self.norm2 = nn.LayerNorm(num_channels)\n",
    "        self.classifier = nn.Linear(num_channels * num_timepoints, output_dim)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # Input shape: (batch_size, num_channels, num_timepoints)\n",
    "        mean = X.mean(dim=2, keepdim=True)\n",
    "        std = X.std(dim=2, keepdim=True)\n",
    "        X_hat = (X - mean) / (std + 1e-5)\n",
    "        \n",
    "        X_tilde = X_hat + self.positional_encoding  # Buffer automatically moves with the model\n",
    "        X_tilde = X_tilde.permute(2, 0, 1)  # (num_timepoints, batch_size, num_channels)\n",
    "        \n",
    "        attn_output, _ = self.multihead_attn(X_tilde, X_tilde, X_tilde)\n",
    "        attn_output = self.dropout(attn_output)\n",
    "        X_ring = torch.stack([self.norm1(a) for a in attn_output], dim=1)\n",
    "        \n",
    "        ff_output = self.ffn(X_ring)\n",
    "        O = self.norm2(ff_output + X_ring)\n",
    "        O_flat = O.view(O.size(0), -1)\n",
    "        output = self.classifier(O_flat)\n",
    "        \n",
    "        return output\n",
    "        \n",
    "# Updated train_model that evaluates training data in eval mode (to disable dropout)\n",
    "# and also saves the softmax probabilities for ROC/PR calculations.\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device):\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "    \n",
    "    # To collect probabilities and labels for further analysis\n",
    "    train_labels_all, val_labels_all = [], []\n",
    "    train_preds_all, val_preds_all = [], []\n",
    "    train_probs_all, val_probs_all = [], []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # --- Training phase (with dropout for weight updates) ---\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for batch_data, batch_labels in train_loader:\n",
    "            batch_data = batch_data.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_data)\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * batch_data.size(0)\n",
    "        \n",
    "        # --- Evaluate training metrics in eval mode (dropout off) ---\n",
    "        model.eval()\n",
    "        correct_train = 0\n",
    "        running_loss_eval = 0.0\n",
    "        epoch_train_probs, epoch_train_preds, epoch_train_labels = [], [], []\n",
    "        with torch.no_grad():\n",
    "            for batch_data, batch_labels in train_loader:\n",
    "                batch_data = batch_data.to(device)\n",
    "                batch_labels = batch_labels.to(device)\n",
    "                \n",
    "                outputs = model(batch_data)\n",
    "                loss = criterion(outputs, batch_labels)\n",
    "                running_loss_eval += loss.item() * batch_data.size(0)\n",
    "                \n",
    "                probs = torch.softmax(outputs, dim=1)[:, 1]\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                correct_train += (preds == batch_labels).sum().item()\n",
    "                \n",
    "                epoch_train_probs.extend(probs.cpu().numpy())\n",
    "                epoch_train_preds.extend(preds.cpu().numpy())\n",
    "                epoch_train_labels.extend(batch_labels.cpu().numpy())\n",
    "        \n",
    "        train_loss_epoch = running_loss_eval / len(train_loader.dataset)\n",
    "        train_accuracy = correct_train / len(train_loader.dataset)\n",
    "        train_losses.append(train_loss_epoch)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        train_labels_all.extend(epoch_train_labels)\n",
    "        train_preds_all.extend(epoch_train_preds)\n",
    "        train_probs_all.extend(epoch_train_probs)\n",
    "        \n",
    "        # --- Validation phase ---\n",
    "        running_loss_val = 0.0\n",
    "        correct_val = 0\n",
    "        epoch_val_probs, epoch_val_preds, epoch_val_labels = [], [], []\n",
    "        with torch.no_grad():\n",
    "            for batch_data, batch_labels in val_loader:\n",
    "                batch_data = batch_data.to(device)\n",
    "                batch_labels = batch_labels.to(device)\n",
    "                \n",
    "                outputs = model(batch_data)\n",
    "                loss = criterion(outputs, batch_labels)\n",
    "                running_loss_val += loss.item() * batch_data.size(0)\n",
    "                \n",
    "                probs = torch.softmax(outputs, dim=1)[:, 1]\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                correct_val += (preds == batch_labels).sum().item()\n",
    "                \n",
    "                epoch_val_probs.extend(probs.cpu().numpy())\n",
    "                epoch_val_preds.extend(preds.cpu().numpy())\n",
    "                epoch_val_labels.extend(batch_labels.cpu().numpy())\n",
    "        \n",
    "        val_loss_epoch = running_loss_val / len(val_loader.dataset)\n",
    "        val_accuracy = correct_val / len(val_loader.dataset)\n",
    "        val_losses.append(val_loss_epoch)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        val_labels_all.extend(epoch_val_labels)\n",
    "        val_preds_all.extend(epoch_val_preds)\n",
    "        val_probs_all.extend(epoch_val_probs)\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
    "              f\"Train Loss: {train_loss_epoch:.4f}, Train Acc: {train_accuracy:.4f} | \"\n",
    "              f\"Val Loss: {val_loss_epoch:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
    "    \n",
    "    return (train_losses, val_losses, train_accuracies, val_accuracies, \n",
    "            train_labels_all, val_labels_all, train_preds_all, val_preds_all, \n",
    "            train_probs_all, val_probs_all)\n",
    "\n",
    "# --- Plotting Functions ---\n",
    "\n",
    "def plot_roc_curve(true_labels, pred_probs, title=\"ROC Curve\"):\n",
    "    fpr, tpr, _ = roc_curve(true_labels, pred_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC Curve (AUC = {roc_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], color='gray', linestyle='--', lw=1)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(alpha=0.5)\n",
    "    plt.savefig(\"CustomTransormer_ROC.png\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "def plot_precision_recall_curve(true_labels, pred_probs, title=\"Precision-Recall Curve\"):\n",
    "    precision, recall, _ = precision_recall_curve(true_labels, pred_probs)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(recall, precision, color='b', lw=2)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(title)\n",
    "    plt.savefig(\"CustomTransormer_Precision-RecallCurve.png\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix_and_metrics(true_labels, preds, title=\"Confusion Matrix\"):\n",
    "    cm = confusion_matrix(true_labels, preds)\n",
    "    \n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(title)\n",
    "    plt.savefig(\"CustomConfusionMatrix.png\", dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    metrics = {}\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    metrics[\"Accuracy\"] = (tp + tn) / (tp + tn + fp + fn)\n",
    "    metrics[\"Precision\"] = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
    "    metrics[\"Recall\"] = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
    "    metrics[\"F1-Score\"] = 2 * (metrics[\"Precision\"] * metrics[\"Recall\"]) / (metrics[\"Precision\"] + metrics[\"Recall\"]) if (metrics[\"Precision\"] + metrics[\"Recall\"]) != 0 else 0\n",
    "    \n",
    "    print(\"\\nModel Metrics:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(true_labels, preds, target_names=['Negative', 'Positive']))\n",
    "\n",
    "def plot_loss_curve(train_losses, val_losses, title=\"Training and Validation Loss\"):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.savefig(\"CustomTrainingandValidationLoss.png\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "def plot_accuracy_curve(train_accuracies, val_accuracies, title=\"Training and Validation Accuracy\"):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(train_accuracies, label='Training Accuracy')\n",
    "    plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.savefig(\"CustomTrainingandValidationAccuracy.png\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "# --- Dataset Definition ---\n",
    "class EEGDatasetFromNumpy(Dataset):\n",
    "    def __init__(self, X_path, y_path):\n",
    "        # Load the data directly from .npy files\n",
    "        self.X = np.load(X_path)\n",
    "        self.y = np.load(y_path)\n",
    "        \n",
    "        # Ensure matching number of samples\n",
    "        assert len(self.X) == len(self.y), \"Mismatch between number of samples in X and y\"\n",
    "        \n",
    "        # Convert to tensors\n",
    "        self.X = torch.tensor(self.X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(self.y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfd4c0f",
   "metadata": {},
   "source": [
    "## Imbalanced Training Pipeline \n",
    "\n",
    "Class imbalance is a common challenge in EEG classification tasks where certain brain state classes are underrepresented compared to others. This imbalance can bias a model toward the majority class, leading to poor predictive performance on minority classes and overall reduced clinical utility. Properly addressing class imbalance is critical to developing reliable models that generalize well across all categories.\n",
    "\n",
    "This code provides an end-to-end pipeline for training and evaluating a Transformer-based EEG classification model with strong emphasis on performance visualization and detailed metrics reporting.\n",
    "\n",
    "\n",
    "**1. Imports and Setup**\n",
    "\n",
    "* Uses PyTorch for deep learning, NumPy for array handling, and scikit-learn for metrics and data splitting.\n",
    "* Matplotlib and Seaborn are used for visualization.\n",
    "\n",
    "**2. Custom EEGTransformer Model**\n",
    "\n",
    "* Implements a Transformer-based neural network for EEG data classification.\n",
    "* Includes positional encoding based on sine and cosine functions for temporal context.\n",
    "* Uses multi-head self-attention, feedforward layers, layer normalization, dropout, and a final linear classifier.\n",
    "* Input shape: `(batch_size, channels, timepoints)`.\n",
    "\n",
    "**3. Dataset Handling**\n",
    "\n",
    "* `EEGDatasetFromNumpy` loads EEG features and labels from `.npy` files, converting them into PyTorch tensors.\n",
    "* Data is split into training and validation subsets using `train_test_split`.\n",
    "\n",
    "**4. Training Loop (`train_model`)**\n",
    "\n",
    "* Alternates between training and evaluation mode per epoch to properly handle dropout and batch normalization.\n",
    "* Collects losses, accuracies, predicted labels, and prediction probabilities for both train and validation sets.\n",
    "* Uses cross-entropy loss and Adam optimizer.\n",
    "\n",
    "**5. Evaluation and Visualization**\n",
    "\n",
    "* Plots training/validation loss and accuracy curves over epochs.\n",
    "* Generates ROC curves, precision-recall curves, and confusion matrices to assess model performance.\n",
    "* Prints detailed classification reports and key metrics (accuracy, precision, recall, F1-score).\n",
    "\n",
    "**6. Model Saving and Inference**\n",
    "\n",
    "* Saves the trained model’s state dictionary.\n",
    "* Demonstrates how to reload the model and set it to evaluation mode for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e3b204-4663-4ebc-b9cb-2246853283e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training Setup ---\n",
    "# (Ensure that you have defined batch_size, num_epochs, and learning_rate)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 32\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Load dataset (update paths as needed)\n",
    "X_path = \"Neontal_eeg_dataset1/annotations/Normalized_Updated_annonated_X_features.npy\"\n",
    "y_path = \"Neontal_eeg_dataset1/annotations/Normalized_Updated_annonated_y_features.npy\"\n",
    "\n",
    "dataset = EEGDatasetFromNumpy(X_path, y_path)\n",
    "print(\"Dataset X shape:\", dataset.X.shape, \"y shape:\", dataset.y.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "indices = list(range(len(dataset)))\n",
    "train_idx, val_idx = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_idx)\n",
    "val_dataset = torch.utils.data.Subset(dataset, val_idx)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize model and training components\n",
    "model = EEGTransformer().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train model\n",
    "(train_losses, val_losses, train_accuracies, val_accuracies, \n",
    " train_labels, val_labels, train_preds, val_preds, \n",
    " train_probs, val_probs) = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device)\n",
    "\n",
    "# Plot curves\n",
    "plot_loss_curve(train_losses, val_losses, title=\"Training and Validation Loss\")\n",
    "plot_accuracy_curve(train_accuracies, val_accuracies, title=\"Training and Validation Accuracy\")\n",
    "plot_roc_curve(val_labels, val_probs, title=\"Validation ROC Curve\")\n",
    "plot_precision_recall_curve(val_labels, val_probs, title=\"Validation Precision-Recall Curve\")\n",
    "plot_confusion_matrix_and_metrics(val_labels, val_preds, title=\"Validation Confusion Matrix\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ccd8bf-21f9-435a-b972-b0bb4d94a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curve(train_losses, val_losses, title=\"Training and Validation Loss\")\n",
    "plot_accuracy_curve(train_accuracies, val_accuracies, title=\"Training and Validation Accuracy\")\n",
    "plot_roc_curve(val_labels, val_probs, title=\"Validation ROC Curve\")\n",
    "plot_precision_recall_curve(val_labels, val_probs, title=\"Validation Precision-Recall Curve\")\n",
    "plot_confusion_matrix_and_metrics(val_labels, val_preds, title=\"Validation Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e8801aa-04bf-42ea-838f-6f5b831c4c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model state dictionary after training\n",
    "torch.save(model.state_dict(), 'custom_neonatal_eeg_transformer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c715e206-f95b-4ccc-bbb1-8110eeead0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inferences\n",
    "# Recreate the model architecture (ensure the parameters match your training setup)\n",
    "model = EEGTransformer(num_channels=18, num_timepoints=64, output_dim=2,\n",
    "                       num_heads=6, intermediate_dim=128, ffn_output_dim=18)\n",
    "\n",
    "# Load the saved weights (make sure to use the same device as your inference)\n",
    "model.load_state_dict(torch.load('custom_neonatal_eeg_transformer.pth', map_location=device))\n",
    "model.to(device)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4e72c1-5064-4b4c-9627-12a347e620d7",
   "metadata": {},
   "source": [
    "Device Management\n",
    " - If you trained your model on a GPU, ensure that during inference your model and data are moved to the correct device (using model.to(device) and input_data.to(device)).\n",
    "\n",
    "Batch Inference\n",
    "- The predict function is written to handle a batch of samples. For a single sample, your input shape should be (1, 18, 64).\n",
    "\n",
    "Data Preprocessing\n",
    "- Make sure any preprocessing (normalization, scaling, etc.) that you applied during training is also applied to new input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdfe011-4bee-42da-b70e-fc7454e57984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance Evaluation\n",
    "def predict(input_data):\n",
    "    \"\"\"\n",
    "    Perform inference on input_data using the loaded model.\n",
    "    \n",
    "    Parameters:\n",
    "        input_data (torch.Tensor): Input tensor of shape (batch_size, num_channels, num_timepoints)\n",
    "        \n",
    "    Returns:\n",
    "        predictions (torch.Tensor): Predicted class indices.\n",
    "        probabilities (torch.Tensor): Softmax probabilities for each class.\n",
    "    \"\"\"\n",
    "    model.eval()  # Ensure the model is in eval mode\n",
    "    with torch.no_grad():\n",
    "        # Move the input to the same device as the model\n",
    "        input_data = input_data.to(device)\n",
    "        outputs = model(input_data)\n",
    "        \n",
    "        # Compute softmax probabilities\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        \n",
    "        # Get the predicted classes (for example, using argmax)\n",
    "        predictions = torch.argmax(probabilities, dim=1)\n",
    "    \n",
    "    return predictions, probabilities\n",
    "\n",
    "# Example usage:\n",
    "# Suppose you have a single sample with shape (1, 18, 64)\n",
    "sample_input = torch.randn(1, 18, 64)  # Replace with your actual data sample\n",
    "\n",
    "# Run prediction\n",
    "predicted_class, pred_probs = predict(sample_input)\n",
    "print(\"Predicted class:\", predicted_class.item())\n",
    "print(\"Prediction probabilities:\", pred_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048a1137-e212-421b-9fa0-0f693f149632",
   "metadata": {},
   "source": [
    "## SMOTE\n",
    "\n",
    "One popular approach to handle imbalance is SMOTE (Synthetic Minority Over-sampling Technique), which artificially increases the number of minority class samples by generating synthetic data points in feature space. In the EEG context, the high-dimensional time-series data is flattened to apply SMOTE, then reshaped back to the original dimensions. This augmentation balances class distributions and allows the model to learn more robust decision boundaries. However, SMOTE modifies the data distribution, which may introduce noise or reduce interpretability.\n",
    "\n",
    "This sections ensures the EEG dataset is balanced with SMOTE before training the Transformer, leading to improved handling of class imbalance and potentially better classification performance. smote.fit_resample(X_flat, y) first \"fits\" the SMOTE algorithm to your data by learning the feature space of the minority class. Then it \"resamples\" the dataset by creating synthetic samples for the minority class so that the overall dataset becomes more balanced.\n",
    "\n",
    "\n",
    "**1. Imports and Setup**\n",
    "\n",
    "* Uses PyTorch, NumPy, Matplotlib, Seaborn for model building, data handling, and visualization.\n",
    "* Incorporates `SMOTE` from imbalanced-learn to address class imbalance.\n",
    "\n",
    "**2. Dataset Preparation**\n",
    "\n",
    "* Original EEG dataset is loaded as a 3D array `(samples, channels, timepoints)` with associated labels.\n",
    "* Flatten each sample into 2D `(samples, features)` to apply SMOTE, which synthesizes new minority class samples.\n",
    "* Reshape the oversampled data back to original 3D EEG format for model input.\n",
    "\n",
    "**3. Visualization of Class Distribution**\n",
    "\n",
    "* Plots class distribution before and after SMOTE to demonstrate balancing effectiveness.\n",
    "* Helps visually confirm that minority class samples are augmented properly.\n",
    "\n",
    "**4. Custom Dataset Class**\n",
    "\n",
    "* `EEGDataset` accepts data arrays directly (post-SMOTE) and converts them to PyTorch tensors.\n",
    "* Provides `__len__` and `__getitem__` for DataLoader compatibility.\n",
    "\n",
    "**5. Data Splitting and Loading**\n",
    "\n",
    "* Splits the balanced dataset into training and validation sets using `train_test_split`.\n",
    "* Creates DataLoaders for batching during training and validation.\n",
    "\n",
    "**6. Model Architecture: EEGTransformer**\n",
    "\n",
    "* Transformer-based model designed for EEG data with positional encoding, multi-head attention, feedforward layers, normalization, dropout, and a linear classification head.\n",
    "* Input shape: `(batch_size, channels, timepoints)`.\n",
    "\n",
    "**7. Training Loop**\n",
    "\n",
    "* Implements training and evaluation phases per epoch, tracking loss, accuracy, predictions, and probabilities.\n",
    "* Uses cross-entropy loss and Adam optimizer.\n",
    "\n",
    "**8. Evaluation and Visualization**\n",
    "\n",
    "* Generates performance plots:\n",
    "\n",
    "  * Training & validation loss and accuracy curves.\n",
    "  * ROC curve and Precision-Recall curve for validation.\n",
    "  * Confusion matrix with detailed classification metrics.\n",
    "\n",
    "**9. Model Saving**\n",
    "\n",
    "* Saves the trained model weights after training completes, allowing for future inference or fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487a77f2-403a-463b-b309-d31cfddb126a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2ca4f5-7ca4-49cb-8fe1-3aac39d7780e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset (update paths as needed)\n",
    "X_path = \"Neontal_eeg_dataset1/annotations/Normalized_Updated_annonated_X_features.npy\"\n",
    "y_path = \"Neontal_eeg_dataset1/annotations/Normalized_Updated_annonated_y_features.npy\"\n",
    "\n",
    "dataset = EEGDatasetFromNumpy(X_path, y_path)\n",
    "print(\"Dataset X shape:\", dataset.X.shape, \"y shape:\", dataset.y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "caef7dcc-c470-4508-a7dd-975fd6e9cded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# Define a Dataset Class that accepts arrays directly\n",
    "# =====================================\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c432197-671d-40fe-a2dc-53d4378c4eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_res, counts_res = np.unique(dataset.y, return_counts=True)\n",
    "plt.figure()\n",
    "plt.bar(unique_res, counts_res, color='salmon')\n",
    "plt.title(\"Class Distribution After SMOTE\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed1050e-b258-42f0-acc6-eca2a4754d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Apply SMOTE ---\n",
    "# SMOTE expects a 2D array, so flatten each sample:\n",
    "n_samples, n_channels, n_timepoints = dataset.X.shape\n",
    "X_flat = dataset.X.reshape((n_samples, -1))\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X_flat, dataset.y)\n",
    "X_res = X_res.reshape((-1, n_channels, n_timepoints))\n",
    "print(\"After SMOTE -> X:\", X_res.shape, \"y:\", y_res.shape)\n",
    "\n",
    "# =====================================\n",
    "# Visualize Class Distribution After SMOTE\n",
    "# =====================================\n",
    "unique_res, counts_res = np.unique(y_res, return_counts=True)\n",
    "plt.figure()\n",
    "plt.bar(unique_res, counts_res, color='salmon')\n",
    "plt.title(\"Class Distribution After SMOTE\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "851a66f4-59a8-4663-85d0-57521441ab56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create dataset from the resampled arrays\n",
    "dataset = EEGDataset(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0c12e4-46f2-479c-85a2-76e2019d8f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training Setup ---\n",
    "# (Ensure that you have defined batch_size, num_epochs, and learning_rate)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 32\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "indices = list(range(len(dataset)))\n",
    "train_idx, val_idx = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_idx)\n",
    "val_dataset = torch.utils.data.Subset(dataset, val_idx)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize model and training components\n",
    "model = EEGTransformer().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train model\n",
    "(train_losses, val_losses, train_accuracies, val_accuracies, \n",
    " train_labels, val_labels, train_preds, val_preds, \n",
    " train_probs, val_probs) = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device)\n",
    "\n",
    "# Plot curves\n",
    "plot_loss_curve(train_losses, val_losses, title=\"Training and Validation Loss\")\n",
    "plot_accuracy_curve(train_accuracies, val_accuracies, title=\"Training and Validation Accuracy\")\n",
    "plot_roc_curve(val_labels, val_probs, title=\"Validation ROC Curve\")\n",
    "plot_precision_recall_curve(val_labels, val_probs, title=\"Validation Precision-Recall Curve\")\n",
    "plot_confusion_matrix_and_metrics(val_labels, val_preds, title=\"Validation Confusion Matrix\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01a363fc-6b59-4f09-99db-efd0c8358c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model state dictionary after training\n",
    "torch.save(model.state_dict(), 'smote_custom_neonatal_eeg_transformer.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac19cf2-a855-4485-966c-ab22ed865137",
   "metadata": {},
   "source": [
    "##  Cost Sentitive Learning \n",
    "An alternative strategy is cost-sensitive learning, where the model is trained using weighted loss functions that assign higher penalties to misclassifications of minority classes without altering the original data. Class weights are computed inversely proportional to class frequencies, making the model “pay more attention” to underrepresented classes during training. This method preserves the dataset’s natural distribution and can improve minority class recognition while avoiding the risks associated with synthetic sample generation.\n",
    "\n",
    "\n",
    "This section customize EEG Transformer pipeline updated to incorporate Cost-Sensitive Learning. \n",
    "Here’s the refined summary for your EEG Transformer pipeline updated to incorporate **Cost-Sensitive Learning** instead of SMOTE:\n",
    "\n",
    "**1. Imports and Setup**\n",
    "\n",
    "* Utilizes PyTorch, NumPy, Matplotlib, Seaborn for deep learning and visualization.\n",
    "* No external resampling method; relies on class weighting during training to handle imbalance.\n",
    "\n",
    "**2. Dataset Preparation**\n",
    "\n",
    "* Creates the `EEGDataset` directly from the original EEG arrays `(samples, channels, timepoints)` and labels, **without any resampling or augmentation**.\n",
    "* This preserves the original data distribution.\n",
    "\n",
    "**3. Data Splitting and Loading**\n",
    "\n",
    "* Splits the dataset into training and validation sets using `train_test_split`.\n",
    "* Creates DataLoaders for efficient batching during training and validation.\n",
    "\n",
    "**4. Cost-Sensitive Learning Setup**\n",
    "\n",
    "* Calculates class weights to penalize the loss function for underrepresented classes more heavily.\n",
    "* Formula used:\n",
    "In all, Cost-Sensitive Learning via Class Weights:\n",
    "\n",
    "We compute class weights using the formula:\n",
    "\n",
    "weight𝑖 = total samples(\n",
    "number of classes\n",
    "×\n",
    "count\n",
    "𝑖\n",
    ")\n",
    "weight \n",
    "i\n",
    "​\n",
    " = \n",
    "(number of classes×count \n",
    "i\n",
    "​\n",
    " )\n",
    "total samples\n",
    "​\n",
    " \n",
    "These weights are passed to nn.CrossEntropyLoss. This causes misclassifications of the minority class to be penalized more during training\n",
    "\n",
    "* Class weights are converted to tensors and moved to the training device (CPU/GPU).\n",
    "\n",
    "**5. Model Architecture: EEGTransformer**\n",
    "\n",
    "* Same Transformer-based architecture tailored for EEG input with positional encoding, multi-head attention, normalization, dropout, and a classification head.\n",
    "* Input dimensions match the dataset shape.\n",
    "\n",
    "**6. Training Loop with Weighted Loss**\n",
    "\n",
    "* Uses `CrossEntropyLoss` with the computed class weights for **cost-sensitive training** to mitigate class imbalance impact.\n",
    "* Tracks training and validation losses, accuracies, and prediction probabilities.\n",
    "\n",
    "**7. Evaluation and Visualization**\n",
    "\n",
    "* Produces comprehensive plots to assess performance:\n",
    "\n",
    "  * Training & validation loss and accuracy curves.\n",
    "  * ROC curve and Precision-Recall curve on validation data.\n",
    "  * Confusion matrix with precision, recall, F1-score, and accuracy metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb6f040-87ab-46bf-a505-a19ef0fc3aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset (update paths as needed)\n",
    "X_path = \"Neontal_eeg_dataset1/annotations/Normalized_Updated_annonated_X_features.npy\"\n",
    "y_path = \"Neontal_eeg_dataset1/annotations/Normalized_Updated_annonated_y_features.npy\"\n",
    "\n",
    "dataset = EEGDatasetFromNumpy(X_path, y_path)\n",
    "print(\"Dataset X shape:\", dataset.X.shape, \"y shape:\", dataset.y.shape)\n",
    "\n",
    "# =====================================\n",
    "# Visualize Class Distribution Before Cost-Sensitive Adjustment\n",
    "# =====================================\n",
    "unique, counts = np.unique(dataset.y, return_counts=True)\n",
    "plt.figure()\n",
    "plt.bar(unique, counts, color='skyblue')\n",
    "plt.title(\"Class Distribution Before Cost-Sensitive Adjustment\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffda2e24-3242-4514-a931-80c58e9a5fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset from the original arrays (no resampling)\n",
    "dataset = EEGDataset(dataset.X, dataset.y)\n",
    "\n",
    "# Split dataset into training and validation sets\n",
    "indices = list(range(len(dataset)))\n",
    "train_idx, val_idx = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_idx)\n",
    "val_dataset   = torch.utils.data.Subset(dataset, val_idx)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# ------------------------------------\n",
    "# Cost-Sensitive Learning: Compute Class Weights\n",
    "# ------------------------------------\n",
    "# Compute weights using the formula:\n",
    "#    weight_i = total_samples / (num_classes * count_i)\n",
    "total_samples = len(dataset.y)\n",
    "num_classes = len(unique)\n",
    "class_weights = [total_samples / (num_classes * count) for count in counts]\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "print(\"Class Weights:\", class_weights)\n",
    "\n",
    "# Initialize model and training components\n",
    "model = EEGTransformer(num_channels=dataset.X.shape[1], num_timepoints=dataset.X.shape[2]).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model using cost-sensitive learning\n",
    "(train_losses, val_losses, train_accuracies, val_accuracies, \n",
    " train_labels, val_labels, train_preds, val_preds, \n",
    " train_probs, val_probs) = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device)\n",
    "\n",
    "# Plot performance curves\n",
    "plot_loss_curve(train_losses, val_losses, title=\"Training and Validation Loss\")\n",
    "plot_accuracy_curve(train_accuracies, val_accuracies, title=\"Training and Validation Accuracy\")\n",
    "plot_roc_curve(val_labels, val_probs, title=\"Validation ROC Curve\")\n",
    "plot_precision_recall_curve(val_labels, val_probs, title=\"Validation Precision-Recall Curve\")\n",
    "plot_confusion_matrix_and_metrics(val_labels, val_preds, title=\"Validation Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "28bef3d5-a840-4a41-ae2e-d694ebd7e572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model state dictionary after training\n",
    "torch.save(model.state_dict(), 'costsenstive_custom_neonatal_eeg_transformer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f1fcfd-7450-4720-9c44-8dbf6498548a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
