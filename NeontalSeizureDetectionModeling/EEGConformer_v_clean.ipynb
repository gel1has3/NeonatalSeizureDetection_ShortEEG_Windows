{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27c729ca",
   "metadata": {},
   "source": [
    "## EEGConformer - Neonatal EGG Seizure detection  \n",
    "\n",
    "This project tackles the challenge of **class imbalance** in neonatal EEG classification, where the dataset naturally contains uneven numbers of samples across different classes. Initially, the raw dataset is loaded and visualized, revealing significant imbalance which can negatively impact model performance by biasing it toward majority classes. To address this, two complementary strategies are employed: **SMOTE (Synthetic Minority Over-sampling Technique)** and **cost-sensitive learning**.\n",
    "\n",
    "In the **SMOTE approach**, the dataset samples are first flattened to a 2D format suitable for synthetic sample generation. SMOTE creates new minority class samples to balance the dataset, which is then reshaped back to the original multi-channel time-series format. This augmented data is split into training and validation sets to train the EEGConformer deep learning model.\n",
    "\n",
    "In parallel, **cost-sensitive learning** keeps the original imbalanced dataset intact but calculates class weights inversely proportional to class frequencies. These weights are used in the loss function to penalize misclassification of minority classes more heavily, guiding the model to pay increased attention to underrepresented classes without modifying the data distribution.\n",
    "\n",
    "Both methods utilize the EEGConformer architecture tailored for EEG time-series data and are trained with the Adam optimizer. During training, various performance metrics such as loss, accuracy, ROC curves, and precision-recall curves are monitored to assess the effectiveness of imbalance handling. The trained models are saved and can be reloaded for evaluation.\n",
    "\n",
    "This combined approach—first acknowledging the natural imbalance, then applying SMOTE for data-level balancing and cost-sensitive learning for algorithm-level adjustment—demonstrates a robust solution for improving classification accuracy on imbalanced EEG datasets.\n",
    "\n",
    "\n",
    "It includes:\n",
    "\n",
    "- Dataset handling\n",
    "\n",
    "- Model definition\n",
    "\n",
    "- Training and evaluation\n",
    "\n",
    "- Visualization and metrics reporting\n",
    "\n",
    "- Saving and loading model checkpoints\n",
    "\n",
    "#### Key Components\n",
    "1. Imports and Libraries\n",
    "- Data Processing: numpy, pandas, mne, scipy, h5py, etc.\n",
    "\n",
    "- Modeling: torch, torch.nn, torch.optim, braindecode.models.EEGConformer\n",
    "\n",
    "- Visualization: matplotlib, seaborn\n",
    "\n",
    "- Evaluation: sklearn.metrics\n",
    "\n",
    "2. Dataset Preparation\n",
    "- Data is loaded from .npy files: EEG features (X) and corresponding labels (y).\n",
    "\n",
    "- Two Dataset classes are defined:\n",
    "\n",
    "- EEGDataset: accepts arrays directly.\n",
    "\n",
    "- EEGDatasetFromNumpy: loads data from disk using file paths.\n",
    "- Class distribution is visualized post-SMOTE to monitor imbalance handling.\n",
    "\n",
    "\n",
    "3. Train-Validation Split\n",
    "- Dataset is split using train_test_split (80/20).\n",
    "\n",
    "- DataLoader is used for batching.\n",
    "\n",
    "4. Model: EEGConformer\n",
    "- Convolution + Transformer-based model specifically designed for EEG signals.\n",
    "\n",
    "Model hyperparameters:\n",
    "\n",
    "- n_filters_time=40\n",
    "\n",
    "- filter_time_length=16\n",
    "\n",
    "- pool_time_length=8, pool_time_stride=4\n",
    "\n",
    "- att_depth=6, att_heads=10\n",
    "\n",
    "- Dropout: 0.5\n",
    "\n",
    "Model is adapted for EEG signals with 18 channels and 64 time steps.\n",
    "\n",
    "5. Training Loop\n",
    "Implements:\n",
    "\n",
    "- Loss tracking (CrossEntropyLoss)\n",
    "\n",
    "- Accuracy calculation\n",
    "\n",
    "- Softmax probability extraction\n",
    "\n",
    "Keeps detailed logs of:\n",
    "\n",
    "- Epoch-wise training/validation loss and accuracy\n",
    "\n",
    "- Predictions and probabilities\n",
    "\n",
    "6. Evaluation & Visualization\n",
    "- ROC Curve\n",
    "\n",
    "- Precision-Recall Curve\n",
    "\n",
    "- Confusion Matrix\n",
    "\n",
    "- Loss and Accuracy Curves\n",
    "\n",
    "Classification Report & Metrics:\n",
    "\n",
    "- Accuracy\n",
    "\n",
    "- Precision\n",
    "\n",
    "- Recall\n",
    "\n",
    "- F1-score\n",
    "\n",
    "7. Model Saving/Loading\n",
    "- Trained model is saved using torch.save.\n",
    "\n",
    "- Reloading is done by reconstructing the architecture and applying load_state_dict.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec1be91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy.io\n",
    "from scipy import signal\n",
    "from scipy.signal import butter, filtfilt, spectrogram\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    roc_curve, auc, precision_recall_curve, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "import h5py\n",
    "import mne\n",
    "from braindecode.models import EEGConformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d643a8",
   "metadata": {},
   "source": [
    " ## EEGConformer - With Imbalanced EEG Dataset\n",
    " \n",
    "The provided code implements a  pipeline for classifying neonatal EEG signals using the **EEGConformer** model from the Braindecode library. It begins by importing a wide range of libraries for data handling, signal processing, deep learning, and evaluation. EEG data is loaded from `.npy` files and encapsulated in custom PyTorch `Dataset` classes. The dataset is split into training and validation sets using `train_test_split`, and batched via `DataLoader`. The core model, EEGConformer, combines convolutional layers and transformer-based attention mechanisms tailored to EEG signal characteristics (with 18 channels and 64 time steps). The training loop tracks loss and accuracy over multiple epochs and evaluates performance using softmax-based predictions. After training, the model is evaluated using various metrics including accuracy, precision, recall, F1-score, and ROC-AUC. Visualization functions are included for plotting loss curves, accuracy trends, ROC and precision-recall curves, and a confusion matrix. The trained model is saved for future use, and a loading routine is provided to restore it for inference. Overall, the code forms a solid and scalable deep learning framework for EEG-based classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51d5d11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4d63f0d-4d2a-4afb-90f9-18e90aca8b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, module=\"mne\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7014765e-52c4-4bfd-929c-bdf9817ee167",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =====================================\n",
    "# Define a Dataset Class that accepts arrays directly\n",
    "# =====================================\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Training Function\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device):\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "    \n",
    "    # To collect probabilities and labels for further analysis\n",
    "    train_labels_all, val_labels_all = [], []\n",
    "    train_preds_all, val_preds_all = [], []\n",
    "    train_probs_all, val_probs_all = [], []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # --- Training phase (with dropout for weight updates) ---\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for batch_data, batch_labels in train_loader:\n",
    "            batch_data = batch_data.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_data)\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * batch_data.size(0)\n",
    "        \n",
    "        # --- Evaluate training metrics in eval mode (dropout off) ---\n",
    "        model.eval()\n",
    "        correct_train = 0\n",
    "        running_loss_eval = 0.0\n",
    "        epoch_train_probs, epoch_train_preds, epoch_train_labels = [], [], []\n",
    "        with torch.no_grad():\n",
    "            for batch_data, batch_labels in train_loader:\n",
    "                batch_data = batch_data.to(device)\n",
    "                batch_labels = batch_labels.to(device)\n",
    "                \n",
    "                outputs = model(batch_data)\n",
    "                loss = criterion(outputs, batch_labels)\n",
    "                running_loss_eval += loss.item() * batch_data.size(0)\n",
    "                \n",
    "                probs = torch.softmax(outputs, dim=1)[:, 1]\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                correct_train += (preds == batch_labels).sum().item()\n",
    "                \n",
    "                epoch_train_probs.extend(probs.cpu().numpy())\n",
    "                epoch_train_preds.extend(preds.cpu().numpy())\n",
    "                epoch_train_labels.extend(batch_labels.cpu().numpy())\n",
    "        \n",
    "        train_loss_epoch = running_loss_eval / len(train_loader.dataset)\n",
    "        train_accuracy = correct_train / len(train_loader.dataset)\n",
    "        train_losses.append(train_loss_epoch)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        train_labels_all.extend(epoch_train_labels)\n",
    "        train_preds_all.extend(epoch_train_preds)\n",
    "        train_probs_all.extend(epoch_train_probs)\n",
    "        \n",
    "        # --- Validation phase ---\n",
    "        running_loss_val = 0.0\n",
    "        correct_val = 0\n",
    "        epoch_val_probs, epoch_val_preds, epoch_val_labels = [], [], []\n",
    "        with torch.no_grad():\n",
    "            for batch_data, batch_labels in val_loader:\n",
    "                batch_data = batch_data.to(device)\n",
    "                batch_labels = batch_labels.to(device)\n",
    "                \n",
    "                outputs = model(batch_data)\n",
    "                loss = criterion(outputs, batch_labels)\n",
    "                running_loss_val += loss.item() * batch_data.size(0)\n",
    "                \n",
    "                probs = torch.softmax(outputs, dim=1)[:, 1]\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                correct_val += (preds == batch_labels).sum().item()\n",
    "                \n",
    "                epoch_val_probs.extend(probs.cpu().numpy())\n",
    "                epoch_val_preds.extend(preds.cpu().numpy())\n",
    "                epoch_val_labels.extend(batch_labels.cpu().numpy())\n",
    "        \n",
    "        val_loss_epoch = running_loss_val / len(val_loader.dataset)\n",
    "        val_accuracy = correct_val / len(val_loader.dataset)\n",
    "        val_losses.append(val_loss_epoch)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        val_labels_all.extend(epoch_val_labels)\n",
    "        val_preds_all.extend(epoch_val_preds)\n",
    "        val_probs_all.extend(epoch_val_probs)\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
    "              f\"Train Loss: {train_loss_epoch:.4f}, Train Acc: {train_accuracy:.4f} | \"\n",
    "              f\"Val Loss: {val_loss_epoch:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
    "    \n",
    "    return (train_losses, val_losses, train_accuracies, val_accuracies, \n",
    "            train_labels_all, val_labels_all, train_preds_all, val_preds_all, \n",
    "            train_probs_all, val_probs_all)\n",
    "    \n",
    "\n",
    "\n",
    "# --- Plotting Functions ---\n",
    "\n",
    "def plot_roc_curve(true_labels, pred_probs, title=\"ROC Curve\"):\n",
    "    fpr, tpr, _ = roc_curve(true_labels, pred_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC Curve (AUC = {roc_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], color='gray', linestyle='--', lw=1)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(alpha=0.5)\n",
    "    plt.savefig(\"EEGConformer_ROC.png\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "def plot_precision_recall_curve(true_labels, pred_probs, title=\"Precision-Recall Curve\"):\n",
    "    precision, recall, _ = precision_recall_curve(true_labels, pred_probs)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(recall, precision, color='b', lw=2)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(title)\n",
    "    plt.savefig(\"EEGConformer_Precision-RecallCurve.png\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix_and_metrics(true_labels, preds, title=\"Confusion Matrix\"):\n",
    "    cm = confusion_matrix(true_labels, preds)\n",
    "    \n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(title)\n",
    "    plt.savefig(\"CustomConfusionMatrix.png\", dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    metrics = {}\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    metrics[\"Accuracy\"] = (tp + tn) / (tp + tn + fp + fn)\n",
    "    metrics[\"Precision\"] = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
    "    metrics[\"Recall\"] = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
    "    metrics[\"F1-Score\"] = 2 * (metrics[\"Precision\"] * metrics[\"Recall\"]) / (metrics[\"Precision\"] + metrics[\"Recall\"]) if (metrics[\"Precision\"] + metrics[\"Recall\"]) != 0 else 0\n",
    "    \n",
    "    print(\"\\nModel Metrics:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(true_labels, preds, target_names=['Negative', 'Positive']))\n",
    "\n",
    "def plot_loss_curve(train_losses, val_losses, title=\"Training and Validation Loss\"):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.savefig(\"EEGConformerTrainingandValidationLoss.png\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "def plot_accuracy_curve(train_accuracies, val_accuracies, title=\"Training and Validation Accuracy\"):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(train_accuracies, label='Training Accuracy')\n",
    "    plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.savefig(\"EEGConformerTrainingandValidationAccuracy.png\", dpi=300)\n",
    "    plt.show()\n",
    "# Set seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a497cbd-730e-4426-a4be-95dfff517a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training Setup ---\n",
    "# (Ensure that you have defined batch_size, num_epochs, and learning_rate)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 64\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "# Load dataset (update paths as needed)\n",
    "X_path = \"Neontal_eeg_dataset1/annotations/EMS_Normalized_annonated_X_features.npy\"\n",
    "y_path = \"Neontal_eeg_dataset1/annotations/EMS_Normalized_annonated_y_features.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56a89e15-ca8b-498d-9a18-722f759db361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# Define a Dataset Class that accepts arrays directly\n",
    "# =====================================\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6306fc6-9cbb-4700-9b27-bbf49e3914f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Dataset Definition ---\n",
    "class EEGDatasetFromNumpy(Dataset):\n",
    "    def __init__(self, X_path, y_path):\n",
    "        # Load the data directly from .npy files\n",
    "        self.X = np.load(X_path)\n",
    "        self.y = np.load(y_path)\n",
    "        \n",
    "        # Ensure matching number of samples\n",
    "        assert len(self.X) == len(self.y), \"Mismatch between number of samples in X and y\"\n",
    "        \n",
    "        # Convert to tensors\n",
    "        self.X = torch.tensor(self.X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(self.y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "dataset = EEGDatasetFromNumpy(X_path, y_path)\n",
    "print(\"Dataset X shape:\", dataset.X.shape, \"y shape:\", dataset.y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b49dbb-4077-4a2c-9a07-8f5747cff5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_res, counts_res = np.unique(dataset.y, return_counts=True)\n",
    "plt.figure()\n",
    "plt.bar(unique_res, counts_res, color='salmon')\n",
    "plt.title(\"Class Distribution After SMOTE\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da7c1b0b-6d19-4989-ac9c-6abf8f99a202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training Setup ---\n",
    "# (Ensure that you have defined batch_size, num_epochs, and learning_rate)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 64\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72afb2c9-c49f-4701-8177-af840ef35883",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## IMBALANCE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7811f65-9bc9-45b7-a473-492d3cb59f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "indices = list(range(len(dataset)))\n",
    "train_idx, val_idx = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_idx)\n",
    "val_dataset = torch.utils.data.Subset(dataset, val_idx)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "from braindecode.models import EEGConformer\n",
    "\n",
    "n_outputs = len(torch.unique(dataset.y))  # Number of classes\n",
    "n_chans = 18  # From your input shape\n",
    "n_times = 64  # From your input shape\n",
    "\n",
    "model = EEGConformer(\n",
    "    n_outputs=n_outputs,\n",
    "    n_chans=n_chans,\n",
    "    n_times=n_times,\n",
    "    n_filters_time=40,           # Default\n",
    "    filter_time_length=16,       # Adjusted for 64 time steps\n",
    "    pool_time_length=8,          # Reduced from default 75\n",
    "    pool_time_stride=4,          # Reduced from default 15\n",
    "    att_depth=6,                 # Default\n",
    "    att_heads=10,                # Default\n",
    "    drop_prob=0.5,               # Default\n",
    "    final_fc_length=\"auto\",      # Automatically inferred\n",
    "    return_features=False,       # Return logits, not features\n",
    ")\n",
    "\n",
    "# Initialize model and training components\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train model\n",
    "(train_losses, val_losses, train_accuracies, val_accuracies, \n",
    " train_labels, val_labels, train_preds, val_preds, \n",
    " train_probs, val_probs) = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device)\n",
    "\n",
    "# Plot curves\n",
    "plot_loss_curve(train_losses, val_losses, title=\"Training and Validation Loss\")\n",
    "plot_accuracy_curve(train_accuracies, val_accuracies, title=\"Training and Validation Accuracy\")\n",
    "plot_roc_curve(val_labels, val_probs, title=\"Validation ROC Curve\")\n",
    "plot_precision_recall_curve(val_labels, val_probs, title=\"Validation Precision-Recall Curve\")\n",
    "plot_confusion_matrix_and_metrics(val_labels, val_preds, title=\"Validation Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a8d4392-cb8e-4db1-9e4e-4774a0b76669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model state dict\n",
    "torch.save(model.state_dict(), \"orig_imb_model_state_conformer_v4.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e8b3f2-7a9e-48b5-8102-ada6929a87ea",
   "metadata": {},
   "outputs": [],
   "source": [
    " # load the model by re-creating the model architecture and then loading the state:\n",
    "# Recreate the model architecture\n",
    "model = EEGConformer(\n",
    "    n_outputs=n_outputs,\n",
    "    n_chans=n_chans,\n",
    "    n_times=n_times,\n",
    "    n_filters_time=40,\n",
    "    filter_time_length=16,\n",
    "    pool_time_length=8,\n",
    "    pool_time_stride=4,\n",
    "    att_depth=6,\n",
    "    att_heads=10,\n",
    "    drop_prob=0.5,\n",
    "    final_fc_length=\"auto\",\n",
    "    return_features=False,\n",
    ")\n",
    "model.load_state_dict(torch.load(\"orig_imb_model_state_conformer_v4.pth\"))\n",
    "model.eval()  # Set to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81da243a-1f24-4d9b-a36f-52146591e075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, if you prefer to save the entire model (which includes the architecture) you can use\n",
    "torch.save(model, \"final_orig_imb_model_state_conformer_v4.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c9ddf0-027a-47ee-8298-8a830037c54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "model = torch.load(\"final_orig_imb_model_state_conformer_v4.pth\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174d792c-9211-457f-a17a-8c1d3d3eea49",
   "metadata": {},
   "source": [
    "## SMOTE\n",
    "\n",
    "This sections incorporates **SMOTE (Synthetic Minority Over-sampling Technique)** to address class imbalance in a neonatal EEG classification task using the **EEGConformer** model. Initially, EEG data is loaded and reshaped into a 2D format as required by SMOTE. The algorithm synthetically generates new samples for the minority class, effectively balancing the dataset. The resampled data is reshaped back into its original 3D EEG format and wrapped in a custom PyTorch `Dataset` class. The new balanced dataset is then split into training and validation sets. The **EEGConformer**, a hybrid deep learning model combining convolutional and attention mechanisms, is instantiated with parameters suited for 18-channel, 64-timepoint EEG inputs. The model is trained using cross-entropy loss and the Adam optimizer, while monitoring training and validation performance over multiple epochs. A suite of visualization functions provides insight into training dynamics (loss and accuracy curves), classification performance (ROC and precision-recall curves), and prediction quality (confusion matrix and metrics). Finally, the model is saved and later reloaded in evaluation mode for further use. This workflow ensures that the classifier is not biased toward the majority class and is better equipped for robust EEG signal classification in imbalanced scenarios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2585361c-9bdc-4e51-857f-3a50488897bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e32bc0-0b94-4d58-885d-290e422d55bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "# --- Apply SMOTE ---\n",
    "# SMOTE expects a 2D array, so flatten each sample:\n",
    "n_samples, n_channels, n_timepoints = dataset.X.shape\n",
    "X_flat = dataset.X.reshape((n_samples, -1))\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X_flat, dataset.y)\n",
    "X_res = X_res.reshape((-1, n_channels, n_timepoints))\n",
    "print(\"After SMOTE -> X:\", X_res.shape, \"y:\", y_res.shape)\n",
    "\n",
    "# =====================================\n",
    "# Visualize Class Distribution After SMOTE\n",
    "# =====================================\n",
    "unique_res, counts_res = np.unique(y_res, return_counts=True)\n",
    "plt.figure()\n",
    "plt.bar(unique_res, counts_res, color='salmon')\n",
    "plt.title(\"Class Distribution After SMOTE\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e16e381b-1765-454d-bc06-1e3b0e7627f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset from the resampled arrays\n",
    "dataset = EEGDataset(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfa014c-92e6-4e9a-99e8-ba78badade14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "indices = list(range(len(dataset)))\n",
    "train_idx, val_idx = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_idx)\n",
    "val_dataset = torch.utils.data.Subset(dataset, val_idx)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "from braindecode.models import EEGConformer\n",
    "\n",
    "n_outputs = len(torch.unique(dataset.y))  # Number of classes\n",
    "n_chans = 18  # From your input shape\n",
    "n_times = 64  # From your input shape\n",
    "\n",
    "model = EEGConformer(\n",
    "    n_outputs=n_outputs,\n",
    "    n_chans=n_chans,\n",
    "    n_times=n_times,\n",
    "    n_filters_time=40,           # Default\n",
    "    filter_time_length=16,       # Adjusted for 64 time steps\n",
    "    pool_time_length=8,          # Reduced from default 75\n",
    "    pool_time_stride=4,          # Reduced from default 15\n",
    "    att_depth=6,                 # Default\n",
    "    att_heads=10,                # Default\n",
    "    drop_prob=0.5,               # Default\n",
    "    final_fc_length=\"auto\",      # Automatically inferred\n",
    "    return_features=False,       # Return logits, not features\n",
    ")\n",
    "\n",
    "# Initialize model and training components\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train model\n",
    "(train_losses, val_losses, train_accuracies, val_accuracies, \n",
    " train_labels, val_labels, train_preds, val_preds, \n",
    " train_probs, val_probs) = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device)\n",
    "\n",
    "# Plot curves\n",
    "plot_loss_curve(train_losses, val_losses, title=\"Training and Validation Loss\")\n",
    "plot_accuracy_curve(train_accuracies, val_accuracies, title=\"Training and Validation Accuracy\")\n",
    "plot_roc_curve(val_labels, val_probs, title=\"Validation ROC Curve\")\n",
    "plot_precision_recall_curve(val_labels, val_probs, title=\"Validation Precision-Recall Curve\")\n",
    "plot_confusion_matrix_and_metrics(val_labels, val_preds, title=\"Validation Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2581eca9-a089-47bd-866b-1c3fb1d87e28",
   "metadata": {},
   "source": [
    "Post visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6c4321a0-b36d-4b53-ab11-2638455763a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model state dict\n",
    "torch.save(model.state_dict(), \"smote_best_model_state_conformer_v4.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed2784c-5062-4acb-a56e-d3d0811761d4",
   "metadata": {},
   "outputs": [],
   "source": [
    " # load the model by re-creating the model architecture and then loading the state:\n",
    "# Recreate the model architecture\n",
    "model = EEGConformer(\n",
    "    n_outputs=n_outputs,\n",
    "    n_chans=n_chans,\n",
    "    n_times=n_times,\n",
    "    n_filters_time=40,\n",
    "    filter_time_length=16,\n",
    "    pool_time_length=8,\n",
    "    pool_time_stride=4,\n",
    "    att_depth=6,\n",
    "    att_heads=10,\n",
    "    drop_prob=0.5,\n",
    "    final_fc_length=\"auto\",\n",
    "    return_features=False,\n",
    ")\n",
    "model.load_state_dict(torch.load(\"smote_best_model_state_conformer_v4.pth\"))\n",
    "model.eval()  # Set to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "881e20a0-52d6-4a31-aac8-695200b26a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, if you prefer to save the entire model (which includes the architecture) you can use\n",
    "torch.save(model, \"final_smote_best_model_state_conformer_v4.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76b81df-f63a-49e7-a7fc-6a38f4145700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "model = torch.load(\"final_smote_best_model_state_conformer_v4.pth\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1913e7-0c67-4ce8-838b-59afac7d54c8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Cost Sensitive Learning\n",
    "\n",
    "This section  implements **cost-sensitive learning (CSL)** to handle class imbalance in a neonatal EEG classification problem using the **EEGConformer** model. The EEG dataset is loaded without resampling, and the original class distribution is visualized. The dataset is then split into training and validation subsets, and data loaders are created for both. To account for class imbalance, class weights are computed inversely proportional to class frequencies, so that minority classes receive higher penalty during training. These weights are passed to the cross-entropy loss function, making the model more sensitive to errors on underrepresented classes. The EEGConformer model, configured for multi-channel time-series EEG input, is trained using the weighted loss and Adam optimizer. Training and validation performance are monitored via loss, accuracy, ROC, precision-recall curves, and confusion matrix visualizations. Finally, the trained model’s state is saved and later reloaded for evaluation, ensuring robust performance on imbalanced EEG classification tasks by explicitly incorporating class-specific costs during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b567f0-60c3-4c24-a9d9-d9d29a93192b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset (update paths as needed)\n",
    "X_path = \"Neontal_eeg_dataset1/annotations/EMS_Normalized_annonated_X_features.npy\"\n",
    "y_path = \"Neontal_eeg_dataset1/annotations/EMS_Normalized_annonated_y_features.npy\"\n",
    "\n",
    "dataset = EEGDatasetFromNumpy(X_path, y_path)\n",
    "print(\"Dataset X shape:\", dataset.X.shape, \"y shape:\", dataset.y.shape)\n",
    "\n",
    "# =====================================\n",
    "# Visualize Class Distribution Before Cost-Sensitive Adjustment\n",
    "# =====================================\n",
    "unique, counts = np.unique(dataset.y, return_counts=True)\n",
    "plt.figure()\n",
    "plt.bar(unique, counts, color='skyblue')\n",
    "plt.title(\"Class Distribution Before Cost-Sensitive Adjustment\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068ef085-cd16-4202-baa0-00b76c72374f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset from the original arrays (no resampling)\n",
    "dataset = EEGDataset(dataset.X, dataset.y)\n",
    "\n",
    "# Split dataset into training and validation sets\n",
    "indices = list(range(len(dataset)))\n",
    "train_idx, val_idx = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_idx)\n",
    "val_dataset   = torch.utils.data.Subset(dataset, val_idx)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# ------------------------------------\n",
    "# Cost-Sensitive Learning: Compute Class Weights\n",
    "# ------------------------------------\n",
    "# Compute weights using the formula:\n",
    "#    weight_i = total_samples / (num_classes * count_i)\n",
    "total_samples = len(dataset.y)\n",
    "num_classes = len(unique)\n",
    "class_weights = [total_samples / (num_classes * count) for count in counts]\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "print(\"Class Weights:\", class_weights)\n",
    "\n",
    "model = EEGConformer(\n",
    "    n_outputs=n_outputs,\n",
    "    n_chans=n_chans,\n",
    "    n_times=n_times,\n",
    "    n_filters_time=40,           # Default\n",
    "    filter_time_length=16,       # Adjusted for 64 time steps\n",
    "    pool_time_length=8,          # Reduced from default 75\n",
    "    pool_time_stride=4,          # Reduced from default 15\n",
    "    att_depth=6,                 # Default\n",
    "    att_heads=10,                # Default\n",
    "    drop_prob=0.5,               # Default\n",
    "    final_fc_length=\"auto\",      # Automatically inferred\n",
    "    return_features=False,       # Return logits, not features\n",
    ")\n",
    "\n",
    "# Initialize model and training components\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights) # wieghts passed for penality of misclassfication\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train model\n",
    "(train_losses, val_losses, train_accuracies, val_accuracies, \n",
    " train_labels, val_labels, train_preds, val_preds, \n",
    " train_probs, val_probs) = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device)\n",
    "\n",
    "# Plot curves\n",
    "plot_loss_curve(train_losses, val_losses, title=\"CSL EEG Conformer Training and Validation Loss\")\n",
    "plot_accuracy_curve(train_accuracies, val_accuracies, title=\"SL EEG Conformer Training and Validation Accuracy\")\n",
    "plot_roc_curve(val_labels, val_probs, title=\"SL EEG Conformer Validation ROC Curve\")\n",
    "plot_precision_recall_curve(val_labels, val_probs, title=\"SL EEG Conformer Validation Precision-Recall Curve\")\n",
    "plot_confusion_matrix_and_metrics(val_labels, val_preds, title=\"SL EEG Conformer Validation Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98bda340-a2dd-4bd8-a1bb-a89f6a33c223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model state dict\n",
    "torch.save(model.state_dict(), \"csl_imb_model_state_conformer_v4.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a35437e-b65b-4b08-b5df-9310fb6355d4",
   "metadata": {},
   "outputs": [],
   "source": [
    " # load the model by re-creating the model architecture and then loading the state:\n",
    "# Recreate the model architecture\n",
    "model = EEGConformer(\n",
    "    n_outputs=n_outputs,\n",
    "    n_chans=n_chans,\n",
    "    n_times=n_times,\n",
    "    n_filters_time=40,\n",
    "    filter_time_length=16,\n",
    "    pool_time_length=8,\n",
    "    pool_time_stride=4,\n",
    "    att_depth=6,\n",
    "    att_heads=10,\n",
    "    drop_prob=0.5,\n",
    "    final_fc_length=\"auto\",\n",
    "    return_features=False,\n",
    ")\n",
    "model.load_state_dict(torch.load(\"csl_imb_model_state_conformer_v4.pth\"))\n",
    "model.eval()  # Set to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d10f60a-af0a-4474-99b4-f7a9f78d2784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, if you prefer to save the entire model (which includes the architecture) you can use\n",
    "torch.save(model, \"final_csl_imb_model_state_conformer_v4.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9179ebd8-a913-49d0-a97e-7bf50eed9ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "model = torch.load(\"final_csl_imb_model_state_conformer_v4.pth\")\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
